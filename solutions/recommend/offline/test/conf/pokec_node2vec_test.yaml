apiVersion: metaspore/v1
kind: Trainingjob
metadata:
  name: fof
  category: Match/Fof
  pipeline_nodes:
    - class: InitSparkNode
      params:
        node_conf: spark
    - class: DataLoaderNode
      params:
        node_conf: dataset
    - class: Node2VecEstimatorNode
      params:
        node_conf: training
    - class: RetrievalEvaluatorNode
      params:
        node_conf: evaluation
    - class: MongoDBDumperNode
      params:
        node_conf: mongodb
    - class: StopSparkNode

spec:
  logging:
    loglevel: debug
  
  spark:
    session_confs:
      app_name: Node2VecEstimatorNode
      local: false
      worker_count: 4
      worker_cpu: 4
      server_count: 2
      server_cpu: 4
      batch_size: 128
      worker_memory: '6G'
      server_memory: '6G'
      coordinator_memory: '6G'
      
    extended_confs:
      spark.network.timeout: '500'
      spark.ui.showConsoleProgress: 'true'
      spark.kubernetes.executor.deleteOnTermination: 'true'
      spark.jars.packages: 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1'
      
    pyzip:
      cwd_path: '/home/spark/work/MetaSpore/'
      zip_file_path: '/home/spark/work/MetaSpore/solutions/recommend/offline/test/python.zip'
            
  dataset:
    train_path: s3://dmetasoul-bucket/demo/datasets/soc-pokec/demo_fg/train_dataset.parquet
    test_path: s3://dmetasoul-bucket/demo/datasets/soc-pokec/demo_fg/test_dataset.parquet
    user_id_column: user_id
    item_id_column: friend_id
    label_column: label
    label_value: '1'

  training:
    node2vec_estimator_class:
      module_name: python.algos.node2vec_retrieval
      class_name: Node2VecEstimator
    model_out_path: s3://dmetasoul-bucket/demo/datasets/soc-pokec/demo_fg/df.parquet
    max_recommendation_count: 20   
    random_walk_p: 2.0
    random_walk_q: 0.5
    random_walk_Z: 1.0
    random_walk_steps: 10
    w2v_vector_size: 5
    w2v_window_size: 30
    w2v_min_count: 0
    w2v_max_iter: 10
    w2v_num_partitions: 1
    euclid_bucket_length: 100
    euclid_distance_threshold: 10

  mongodb:
    uri: mongodb://172.31.37.47:27017/
    database: jpa
    collection: saas_fof
    write_mode: overwrite
    index_fields: []
    index_unique: False
    
  spark_stop:
  