apiVersion: metaspore/v1
kind: TrainingJob
metadata:
  name: BatchNegativeSampling
  category: Match/TwoTwoers/DSSM
  pipeline_nodes:
    - class: InitSparkNode
      params:
        node_conf: spark
    - class: DataLoaderNode
      params:
        node_conf: dataset
    - class: TwoTowersEstimatorNode
      params:
        node_conf: training
    - class: RetrievalEvaluatorNode
      params:
        node_conf: evaluation
    - class: StopSparkNode

spec:
  logging:
    loglevel: debug

  spark:
    session_confs:
      app_name: 'Two Towers Pipeline Demo'
      local: False
      worker_count: 2
      worker_cpu: 4
      server_count: 2
      server_cpu: 4
      batch_size: 128
      worker_memory: '6G'
      server_memory: '6G'
      coordinator_memory: '6G'

    extended_confs:
      spark.network.timeout: '500'
      spark.ui.showConsoleProgress: 'true'
      spark.kubernetes.executor.deleteOnTermination: 'true'

    pyzip:
      cwd_path: '/home/spark/work/MetaSpore/'
      zip_file_path: '/home/spark/work/MetaSpore/solutions/recommend/offline/test/python.zip'
  
  dataset:
    train_path: s3://dmetasoul-bucket/demo/movielens/1m/negsample/prob/train.parquet
    test_path: s3://dmetasoul-bucket/demo/movielens/1m/negsample/num_negs_10/test.parquet
    item_path: s3://dmetasoul-bucket/demo/datasets/movielens/1m/negsample/prob/item.parquet

  training:
    user_module_class:
      module_name: python.algos.twotower.dssm
      class_name: UserModule

    item_module_class:
      module_name: python.algos.twotower.dssm
      class_name: ItemModule

    similarity_module_class:
      module_name: python.algos.twotower.dssm
      class_name: SimilarityModule

    two_towers_retrieval_module_class:
      module_name: python.algos.twotower.dssm
      class_name: TwoTowerBatchNegativeSamplingModule

    two_towers_agent_class:
      module_name: python.algos.twotower.dssm
      class_name: TwoTowerBatchNegativeSamplingAgent

    two_towers_estimator_class:
      module_name: metaspore
      class_name: TwoTowerRetrievalEstimator

    user_column_name: s3://dmetasoul-bucket/demo//movielens/1m/schema/dssm/user_column_schema
    user_combine_schema: s3://dmetasoul-bucket/demo/movielens/1m/schema/dssm/user_combine_schema
    item_column_name: s3://dmetasoul-bucket/demo/movielens/1m/schema/dssm/item_column_schema
    item_combine_schema: s3://dmetasoul-bucket/demo/movielens/1m/schema/dssm/item_combine_schema
    model_in_path: null
    model_out_path: s3://dmetasoul-bucket/demo/movielens/1m/model/dssm/model_out/
    # model_export_path: s3://dmetasoul-bucket/demo/movielens/1m/model/dssm/model_export/
    model_export_path: null
    model_version: '0.1'
    experiment_name: movielens1m_two_towers_dssm

    ## milvus
    milvus_description: 'ml_1m_dssm'
    milvus_host: 'my-milvus-release.milvus.svc.cluster.local'
    milvus_port: '19530'
    milvus_embedding_field: 'embedding_vector'
    milvus_index_type: 'IVF_FLAT'
    milvus_metric_type: 'IP'
    milvus_nlist: 1024
    milvus_nprobe: 128

    ## dataset
    input_label_column_index: 0
    input_item_id_column_index: 6 
    input_feature_column_num: 11
    input_item_probability_column_index: 11
    input_sample_weight_column_index: 12

    ## model hyper params
    tau: 0.05
    use_remove_accidental_hits: True
    use_sampling_probability_correction: True
    use_sample_weight: True
    sparse_init_var: 0.0001
    net_dropout: 0.0
    batch_size: 256
    vector_embedding_size: 32
    item_embedding_size: 128
    dnn_hidden_units: [512, 256, 128]
    dnn_hidden_activations: 'ReLU'
    adam_learning_rate: 0.00005
    ftrl_learning_rate: 0.02
    ftrl_smothing_rate: 1.0
    ftrl_l1_regularization: 1.0
    ftrl_l2_regularization: 1.0
    training_epoches: 5
    shuffle_training_dataset: True

  evaluation:

  spark_stop:
  