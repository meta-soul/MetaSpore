{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58d992-1710-4bb1-80e5-2e40de424b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import argparse\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType, StringType, ArrayType\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86880e-decc-45ba-9e7c-b72bfa5ac052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    params = dict()\n",
    "    with open(path, 'r') as stream:\n",
    "        params = yaml.load(stream, Loader=yaml.FullLoader)\n",
    "    return params\n",
    "\n",
    "def init_spark():\n",
    "    spark = (SparkSession.builder\n",
    "        .appName('Elastic Search')\n",
    "        .master('local')\n",
    "        .config(\"spark.executor.memory\",\"4G\")\n",
    "        .config(\"spark.executor.instances\",\"2\")\n",
    "        .config(\"spark.network.timeout\",\"500\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"2G\")\n",
    "        .getOrCreate())\n",
    "    \n",
    "    sc = spark.sparkContext\n",
    "    print('Debug -- spark init')\n",
    "    print('Debug -- version:', sc.version)   \n",
    "    print('Debug -- applicaitonId:', sc.applicationId)\n",
    "    print('Debug -- uiWebUrl:', sc.uiWebUrl)\n",
    "    return spark\n",
    "\n",
    "def stop_spark(spark):\n",
    "    print('Debug -- spark stop')\n",
    "    spark.sparkContext.stop()\n",
    "\n",
    "def read_dataset(movies_path, ratings_path, users_path, imdb_path, douban_movies_path, **kwargs):\n",
    "    ### read movies\n",
    "    movies_schema = StructType([\n",
    "            StructField(\"movie_id\", LongType(), True),\n",
    "            StructField(\"title\", StringType(), True),\n",
    "            StructField(\"genre\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    movies = spark.read.csv(movies_path, sep='::',inferSchema=False, header=False, schema=movies_schema)\n",
    "\n",
    "    ### read ratings\n",
    "    ratings_schema = StructType([\n",
    "            StructField(\"user_id\", LongType(), True),\n",
    "            StructField(\"movie_id\", LongType(), True),\n",
    "            StructField(\"rating\", FloatType(), True),\n",
    "            StructField(\"timestamp\", LongType(), True)\n",
    "    ])\n",
    "\n",
    "    ratings = spark.read.csv(ratings_path, sep='::', inferSchema=False, header=False, schema=ratings_schema)\n",
    "    \n",
    "    ### read users\n",
    "    users_schema = StructType([\n",
    "            StructField(\"user_id\", LongType(), True),\n",
    "            StructField(\"gender\", StringType(), True),\n",
    "            StructField(\"age\", IntegerType(), True),\n",
    "            StructField(\"occupation\", StringType(), True),\n",
    "            StructField(\"zip\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    users = spark.read.csv(users_path, sep='::', inferSchema=False, header=False, schema=users_schema)\n",
    "\n",
    "    ### read imdb datasets\n",
    "    imdb = spark.read.csv(imdb_path, sep=r'\\t', inferSchema=False, header=True)\n",
    "    imdb = imdb.withColumn('imdb_url', F.concat(F.lit(\"https://www.imdb.com/title/\"), F.col(\"tconst\"), F.lit(\"/\")))\n",
    "\n",
    "    ### read douban movie datasets\n",
    "    douban_movies = spark.read.csv(douban_movies_path, sep=',',inferSchema=True, header=True)\n",
    "    \n",
    "    return users, movies, ratings, imdb, douban_movies\n",
    "\n",
    "\n",
    "def write_parquet_dataset(movies, ratings, users, douban_movies, \\\n",
    "                          movies_parquet_path, ratings_parquet_path, users_parquet_path, douban_movies_parquet_path, **kwargs):\n",
    "    movies.write.parquet(movies_parquet_path, mode=\"overwrite\")\n",
    "    ratings.write.parquet(ratings_parquet_path, mode=\"overwrite\")\n",
    "    users.write.parquet(users_parquet_path, mode=\"overwrite\")\n",
    "    douban_movies.write.parquet(douban_movies_parquet_path, mode=\"overwrite\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fedb7c-8f46-4210-9cc6-c83ea67ffa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_config(\"es_dev.yaml\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745ea49-3659-42ac-aa8b-fcd047d2e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd70c1-9d09-49ae-baf9-0693db583e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users, movies, ratings, imdb, douban_movies = read_dataset(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e350d76-3b98-428e-bb27-28561170ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a5103-4967-4beb-b76e-2796342c1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37893561-34b2-4451-83b8-b1f9f4a7bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "extract_genres = udf(lambda x: x.lower().split(\"|\"), ArrayType(StringType()))\n",
    "raw_movies = movies\n",
    "movies = raw_movies.select(\"movie_id\", \"title\", extract_genres(\"genre\").alias(\"genre\"))\n",
    "movies.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151a03c-c0e6-4c53-bfd5-08df66c06694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a700d-fb70-4d66-9847-7975e94a8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "douban_movies.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7427d3-b6a1-4578-9d26-2dd7f93fe8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "douban_movies=douban_movies.select('MOVIE_ID', 'NAME', 'STORYLINE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de97c3-b906-4848-a7d3-fcf713dc02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet_dataset(movies, ratings, users, douban_movies, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c251129-1dec-4803-8d98-34d660a67146",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://dmetasoul-bucket/demo/movielens/ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824c4e3-9f5d-45a3-9f30-7fe79d700124",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://dmetasoul-bucket/demo/datasets/moviedata-10m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935c8a3-18ad-463f-991f-cbfa58da1bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ae9b2-8707-4a10-b290-69eb3b2a00bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
