scene-config:
  scenes:
    - name: questionAnswer
      layers:
        - name: qp.qa
          normalLayerArgs:
            - experimentName: qp.qa.base
              ratio: 1.0
        - name: match.qa
          normalLayerArgs:
            - experimentName: match.qa.base
              ratio: 1.0
        - name: rank.qa
          normalLayerArgs:
            - experimentName: rank.qa.base
              ratio: 1.0
        - name: summary.qa
          normalLayerArgs:
            - experimentName: summary.qa.base
              ratio: 1.0
    - name: textToImage
      layers:
        - name: qp.t2i
          normalLayerArgs:
            - experimentName: qp.t2i.base
              ratio: 1.0
        - name: match.t2i
          normalLayerArgs:
            - experimentName: match.t2i.base
              ratio: 1.0
        - name: rank.t2i
          normalLayerArgs:
            - experimentName: rank.t2i.base
              ratio: 1.0
        - name: summary.t2i
          normalLayerArgs:
            - experimentName: summary.t2i.base
              ratio: 1.0

  experiments:
    # QuestionAnswer experiments
    - layerName: qp.qa
      experimentName: qp.qa.base
      extraExperimentArgs:
        modelName: sbert-chinese-qmc-domain-v1
        processorName: HfTokenizerProcessor
    - layerName: match.qa
      experimentName: match.qa.base
      extraExperimentArgs:
        modelName: sbert-chinese-qmc-domain-v1
        vectorName: sentence_embedding
        matcherNames: [ANNMatcher]
        maxReservation: 200
        milvusArgs:
          collectionName: baike_qa_demo
          outFields: id
          vectorField: question_emb
          searchParams: "{\"nprobe\":128}"
    - layerName: rank.qa
      experimentName: rank.qa.base
      extraExperimentArgs:
        maxReservation: 5
    - layerName: summary.qa
      experimentName: summary.qa.base
      extraExperimentArgs:
        summaryFields: [question, answer, category]
    # TxtToImg experiments
    - layerName: qp.t2i
      experimentName: qp.t2i.base
      extraExperimentArgs:
        modelName: clip-text-encoder-v1
        processorName: HfTokenizerProcessor
    - layerName: match.t2i
      experimentName: match.t2i.base
      extraExperimentArgs:
        modelName: clip-text-encoder-v1
        vectorName: sentence_embedding
        matcherNames: [ANNMatcher]
        maxReservation: 200
        milvusArgs:
          collectionName: txt_to_img_demo
          outFields: id
          vectorField: image_emb
          searchParams: "{\"nprobe\":128}"
    - layerName: rank.t2i
      experimentName: rank.t2i.base
      extraExperimentArgs:
        maxReservation: 20
    - layerName: summary.t2i
      experimentName: summary.t2i.base
      extraExperimentArgs:
        summaryFields: [name, url]