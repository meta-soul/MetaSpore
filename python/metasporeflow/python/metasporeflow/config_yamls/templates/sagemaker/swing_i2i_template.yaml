apiVersion: metaspore/v1
kind: TrainingJob
metadata:
  name: ItemCF
  category: Match/I2I/Swing

spec:
  logging:
    loglevel: {{loglevel | default('debug')}}

  spark:
    session_confs:
      app_name: 'Ecommerce Swing I2I Pipeline'
      local: {{local | default(True)}}
      worker_count: {{worker_count | default(8)}}
      worker_cpu: {{worker_cpu | default(1)}}
      server_count: {{server_count | default(8)}}
      server_cpu: {{server_cpu | default(1)}}
      batch_size: {{batch_size | default(256)}}
      worker_memory: {{worker_memory | default('1G')}}
      server_memory: {{server_memeory | default('1G')}}
      coordinator_memory: {{coordinator_memory | default('16G')}}
    extended_confs:
      spark.network.timeout: '500'
      spark.ui.showConsoleProgress: 'true'
      spark.kubernetes.executor.deleteOnTermination: 'true'
      spark.hadoop.fs.s3a.aws.credentials.provider: com.amazonaws.auth.DefaultAWSCredentialsProviderChain
      spark.default.parallelism: '16'
      spark.sql.shuffle.partitions: '16'
      spark.hadoop.fs.s3a.committer.name: 'directory'
      spark.hadoop.fs.s3a.committer.threads: '16'
      spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version": '2'
      spark.hadoop.fs.s3a.committer.staging.conflict-mode: 'append'
      spark.hadoop.fs.s3a.threads.max: '32'
      spark.hadoop.fs.s3a.connection.maximum: '32'
      spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a: 'org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory'

  dataset: 
    train_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/data/match/icf/@{METASPORE_FLOW_MODEL_VERSION}/train.parquet'
    test_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/data/match/icf/@{METASPORE_FLOW_MODEL_VERSION}/test.parquet'
    fmt: {{dataset_fmt | default('parquet')}}

  training: 
    i2i_estimator_class: metaspore.algos.item_cf_retrieval.ItemCFEstimator
    i2i_estimator_config_class: metaspore.algos.pipeline.ItemCFEstimatorConfig
    estimator_params:
      max_recommendation_count: {{max_recommendation_count}}

  mongodb: 
    uri: {{mongodb_uri}}
    database: {{mongodb_db}}
    write_mode: overwrite
    index_fields: [key]
    index_unique: False
    collection: {{mongodb_collection}}
