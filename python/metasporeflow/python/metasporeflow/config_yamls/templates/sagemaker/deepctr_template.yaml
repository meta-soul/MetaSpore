apiVersion: metaspore/v1
kind: TrainingJob
metadata:
  name: WideDeep
  category: Rank/DeepCTR/WideDeep

spec:
  logging:
    loglevel: {{loglevel | default('debug')}}

  spark:
    session_confs:
      app_name: Ecommerce Deep CTR Pipeline
      local: {{local | default(True)}}
      worker_count: {{worker_count | default(8)}}
      worker_cpu: {{worker_cpu | default(1)}}
      server_count: {{server_count | default(8)}}
      server_cpu: {{server_cpu | default(1)}}
      batch_size: {{batch_size | default(256)}}
      worker_memory: {{worker_memory | default('1G')}}
      server_memory: {{server_memeory | default('1G')}}
      coordinator_memory: {{coordinator_memory | default('16G')}}
    extended_confs:
      spark.network.timeout: '500'
      spark.ui.showConsoleProgress: 'true'
      spark.kubernetes.executor.deleteOnTermination: 'true'
      spark.hadoop.fs.s3a.aws.credentials.provider: com.amazonaws.auth.DefaultAWSCredentialsProviderChain
      spark.default.parallelism: '16'
      spark.sql.shuffle.partitions: '16'
      spark.hadoop.fs.s3a.committer.name: 'directory'
      spark.hadoop.fs.s3a.committer.threads: '16'
      spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version": '2'
      spark.hadoop.fs.s3a.committer.staging.conflict-mode: 'append'
      spark.hadoop.fs.s3a.threads.max: '32'
      spark.hadoop.fs.s3a.connection.maximum: '32'
      spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a: 'org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory'

  dataset:
    train_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/data/ctr/nn/@{METASPORE_FLOW_MODEL_VERSION}/train.parquet'
    test_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/data/ctr/nn/@{METASPORE_FLOW_MODEL_VERSION}/test.parquet'

  training:
    deep_ctr_model_class: metaspore.algos.widedeep_net.WideDeep
    estimator_config_class: metaspore.algos.pipeline.DeepCTREstimatorConfig
    model_config_class: metaspore.algos.pipeline.WideDeepConfig
    model_params: 
      wide_combine_schema_path: {{wide_combine_schema_path}}
      deep_combine_schema_path: {{deep_combine_schema_path}}
      use_wide: True
      use_dnn: True
      wide_embedding_dim: 16
      deep_embedding_dim: 16
      ftrl_l1: 1.0
      ftrl_l2: 120.0
      ftrl_alpha: 1.0
      ftrl_beta: 1.0
      dnn_hidden_units: [256, 256, 256]
      sparse_init_var: 0.01
      dnn_hidden_activations: ReLU
      use_bias: True
      batch_norm: True
      net_dropout: 0
      net_regularizer: null
    
    estimator_params:
      model_in_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/model/checkpoint/@{METASPORE_FLOW_LAST_MODEL_VERSION}/@{METASPORE_FLOW_MODEL_NAME}/'
      model_out_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/model/checkpoint/@{METASPORE_FLOW_MODEL_VERSION}/@{METASPORE_FLOW_MODEL_NAME}/'
      model_export_path: '@{METASPORE_FLOW_S3_WORK_DIR}/flow/scene/@{METASPORE_FLOW_SCENE_NAME}/model/export/@{METASPORE_FLOW_MODEL_VERSION}/@{METASPORE_FLOW_MODEL_NAME}/'
      model_version: '@{METASPORE_FLOW_MODEL_VERSION}'
      experiment_name: '@{METASPORE_FLOW_MODEL_NAME}'
      input_label_column_index: 0
      metric_update_interval: 100
      adam_learning_rate: 0.0001
      training_epoches: 1
      shuffle_training_dataset: True

