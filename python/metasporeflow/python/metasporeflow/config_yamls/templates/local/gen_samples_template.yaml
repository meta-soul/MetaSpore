apiVersion: metaspore/v1
kind: TrainingJob
metadata:
  name: SampleGeneration
  category: Dataset/SampleGeneration

spec:
  logging:
    loglevel: {{loglevel | default('debug')}}

  init_spark:
    session_conf:
      app_name: 'Ecommerce Samples'
      local: {{local | default(True)}}
      worker_count: {{worker_count | default(1)}}
      worker_cpu: {{worker_cpu | default(2)}}
      server_count: {{server_count | default(1)}}
      server_cpu: {{server_cpu | default(2)}}
      batch_size: {{batch_size | default(256)}}
      worker_memory: {{worker_memory | default('4G')}}
      server_memory: {{server_memeory | default('4G')}}
      coordinator_memory: {{coordinator_memory | default('2G')}}
    extended_conf:
      spark.network.timeout: '500'
      spark.ui.showConsoleProgress: 'true'
      spark.kubernetes.executor.deleteOnTermination: 'true'
      spark.jars.packages: 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1'
      spark.default.parallelism: {{spark_default_parallelism | default('"10"')}}
      spark.sql.shuffle.partitions: {{spark_sql_shuffle_partitions | default('"10"')}}

  load_dataset: 
    user_path: {{user_path}}
    item_path: {{item_path}}
    interaction_path: {{interaction_path}}
    fmt: {{fmt | default('parquet')}}

  join_dataset:
    join_on: 
      user_key: {{user_key}}
      item_key: {{item_key}}
      timestamp: {{timestamp_key}}
    user_bhv_seq:
      max_len: {{max_len | default(10)}}
    negative_sample:
      sample_ratio: {{sample_ratio | default(3)}}

  gen_feature:
    reserve_only_cate_cols: True

  gen_sample:
    - model_type: ctr_nn
      split_test: 0.15
      shuffle: True
      fmt: parquet
      train_path: {{ctr_nn_train_path}}
      test_path: {{ctr_nn_test_path}}
    
    - model_type: match_icf
      split_test: 0.15
      shuffle: True
      fmt: parquet
      train_path: {{match_icf_train_path}}
      test_path: {{match_icf_test_path}}

    # not use for now
    - model_type: ctr_gbm
      split_test: 0.15
      use_shuffle: True
      fmt: parquet
      combine_schema:
        user_cols: [user_id]
        item_cols: [item_id, category]
        combine_cols: []
      train_path: /opt/volumes/output/data/ctr/gbm/train.parquet
      test_path: /opt/volumes/output/data/ctr/gbm/test.parquet

    # not use for now
    - model_type: match_nn
      split_test: 0.15
      shuffle: True
      fmt: parquet
      train_path: /opt/volumes/output/data/match/nn/train.parquet
      test_path: /opt/volumes/output/data/match/nn/test.parquet
      item_path: /opt/volumes/output/data/match/nn/item.parquet

  dump_nn_feature: 
    mongodb:
      uri: {{mongodb_uri}}
      database: {{mongodb_db}}
      write_mode: overwrite
      index_fields: []
      index_unique: False
    tables:
      - feature_column: {{user_feature_columns}}
        mongo_collection: {{user_feature_collection}}
        drop_duplicates_by: [user_id]
      - feature_column: {{item_feature_columns}}
        mongo_collection: {{item_feature_collection}} 
        drop_duplicates_by: [item_id]
      - feature_column: {{item_summary_columns}}
        mongo_collection: {{item_summary_collection}} 
        drop_duplicates_by: [item_id]

  # not use for now
  dump_lgb_feaure:
    mongodb:
      uri: mongodb://root:test_mongodb_123456@localhost:27018/?authSource=admin
      database: jpa
      write_mode: overwrite
      index_fields: []
      index_unique: False
    tables:
      - feature_column: user_cols
        mongo_collection: amazonfashion_user_lgb_feature
      - feature_column: item_cols
        mongo_collection: amazonfashion_item_lgb_feature
